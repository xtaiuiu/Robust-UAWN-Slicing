import time

import numpy as np
import scipy.linalg as lg
import cvxpy as cp

from utils.gradient_projection_methods.example_problems import BoundProblem


def gradient_projection(prob, x0, eps=1e-8):
    """
    optimize a bound-constrained problem by gradient projection method.
    Stepsize rule is generated by
    :param prob: must be a BoundProblem object
    :param stepsize_rule: a callable
    :return: f_opt, x_opt
    """
    alpha, gamma = 1.0, 0.5
    f0, g0 = prob.f(x0), prob.g(x0)
    x = np.maximum(prob.q, x0 - alpha * g0)
    fx = prob.f(x)
    n, n_max = 0, 100000
    while abs((f0 - fx)/fx) > eps and n < n_max:
        gx = prob.g(x)
        print(f"n = {n}, f0 = {f0}, fx = {fx}, norm_gx = {lg.norm(gx)}, alpha = {alpha}")
        # eventually constant stepsize rule
        # while fx > f0 + np.dot(g0, x - x0) + lg.norm(x - x0)**2/(2*alpha):
        #     alpha *= gamma
        alpha = armijo_rule(prob, x, fx, gx)
        x0 = x
        f0, g0 = prob.f(x0), prob.g(x0)
        x = np.maximum(prob.q, x - alpha * g0)
        fx = prob.f(x)
        n += 1
    return fx, x


def gradient_projection_extrapolation(prob, x0, eps=1e-8):
    alpha, gamma = 0.1, 0.5
    f0, g0 = prob.f(x0), prob.g(x0)
    x = np.maximum(prob.q, x0 - alpha * g0)
    fx = prob.f(x)
    k, k_max = 1, 100000
    while (abs((f0 - fx)/fx) > eps) and k < k_max:
        print(f"k = {k}, f0 = {f0}, fx = {fx}, alpha = {alpha}")
        beta = (k-1)/(k+2)
        y = x + beta * (x - x0)
        # eventually constant stepsize rule
        fy, gy = prob.f(y), prob.g(y)
        x_tmp = np.maximum(prob.q, y - alpha * gy)
        f_tmp = prob.f(x_tmp)
        while f_tmp > fy + np.dot(gy, x_tmp - y) + lg.norm(x_tmp - y)**2/(2*alpha):
            alpha *= gamma
            x_tmp = np.maximum(prob.q, y - alpha * gy)
            f_tmp = prob.f(x_tmp)
        x0 = x
        x = x_tmp
        f0, fx = prob.f(x0), f_tmp
        k += 1
    print(f"gp finished in {k} iterations")
    return fx, x

def armijo_rule(prob, x, f, g, beta=0.5, sigma=0.7):
    s = 4.0
    m_max = 100
    for m in range(m_max):
        x_k_alpha = np.maximum(prob.p_u, x - beta ** m * s * g)
        if f - prob.f(x_k_alpha) >= sigma * np.dot(g, x - x_k_alpha):
            break
    return beta**m*s


def cvx_optimize(prob):
    x = cp.Variable(shape=len(prob.a))
    z = cp.sum(cp.multiply(prob.a, x)) - prob.p

    obj = 0.5*cp.square(z) + prob.lam * z - cp.sum(cp.multiply(prob.w, cp.log1p(cp.multiply(prob.b, x))))
    constraints = [x >= prob.q]
    problem = cp.Problem(cp.Minimize(obj), constraints)
    problem.solve(solver=cp.CLARABEL)
    print(f"cvx: f = {problem.value}")
    return problem.value, x.value


if __name__ == '__main__':
    #np.random.seed(1)
    n = np.random.choice([400, 600])
    a = np.random.randint(1, 10, n)
    b = np.random.randint(2, 10, n)
    w = np.random.randint(2, 20, n)
    p = np.random.choice([300, 600, 800])
    q = np.random.randint(2, 10, n)*0.1
    lam = 0.25
    problem = BoundProblem(a, b, lam, p, q, w)
    t1 = time.perf_counter()
    fx, x = gradient_projection_extrapolation(problem, q)
    print(f" pg time = {time.perf_counter() - t1}, pg f = {fx}")
    t1 = time.perf_counter()
    fx, x = gradient_projection(problem, q)
    #fx, x = cvx_optimize(problem)
    print(f" cvx time = {time.perf_counter() - t1}, cvx f = {fx}")
